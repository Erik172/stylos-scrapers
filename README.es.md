# Stylos Scraper ğŸ•·ï¸ğŸ‘—

**Parte del ecosistema Stylos** - Scraper inteligente para sitios de moda con arquitectura distribuida.

[English](README.md)

<!-- GIF -->
![Zara Scraper Demo](media/zara-demo.gif)

[![Version](https://img.shields.io/badge/version-1.2.3-blue.svg)](https://github.com/erik172/stylos-scrapers)
[![Python](https://img.shields.io/badge/python-3.11%2B-blue.svg)](https://python.org)
[![Scrapy](https://img.shields.io/badge/scrapy-2.13.2-green.svg)](https://scrapy.org)
[![Docker](https://img.shields.io/badge/docker-enabled-blue.svg)](https://docker.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Stylos Scraper es una **soluciÃ³n profesional de web scraping distribuida** diseÃ±ada especÃ­ficamente para la extracciÃ³n masiva de datos de sitios de e-commerce de moda. Utiliza tecnologÃ­as avanzadas como **Selenium Grid**, **Scrapyd**, **FastAPI** y **Docker** para crear un sistema escalable y robusto capaz de manejar mÃºltiples sitios web simultÃ¡neamente.

Este proyecto forma parte del ecosistema **Stylos**, una plataforma de inteligencia artificial que analiza tendencias de moda y genera recomendaciones personalizadas basada en diferentes estilos (Old Money, Formal, Streetwear, y muchos mÃ¡s).

<p align="center">
  <a href="#-caracterÃ­sticas-principales">CaracterÃ­sticas Principales</a> â€¢
  <a href="#-inicio-rÃ¡pido-con-docker">Inicio RÃ¡pido</a> â€¢
  <a href="#-uso-bÃ¡sico">Uso</a> â€¢
  <a href="#-contribuciÃ³n">ContribuciÃ³n</a> â€¢
  <a href="#-licencia">Licencia</a> â€¢
  <a href="#-documentaciÃ³n-detallada">Docs Detallados</a>
</p>

---

## âœ¨ CaracterÃ­sticas Principales

- ğŸŒ **Soporte Multi-PaÃ­s/Multi-Idioma**: ExtracciÃ³n internacional de Zara con parÃ¡metros dinÃ¡micos.
- ğŸ’± **Sistema Multi-Moneda AutomÃ¡tico**: DetecciÃ³n automÃ¡tica de monedas por paÃ­s (USD, EUR, COP, etc.).
- ğŸ¯ **Sistema de Extractors Modular**: Arquitectura pluggable para fÃ¡cil extensiÃ³n a nuevos retailers.
- ğŸ³ **Completamente Dockerizado**: Arquitectura Cloud-Native con orquestaciÃ³n automÃ¡tica vÃ­a Docker Compose.
- ğŸš€ **Scraping Distribuido**: Usa Selenium Grid para automatizaciÃ³n de navegadores en paralelo.
- ğŸ® **Controlador CLI Avanzado**: Una interfaz de lÃ­nea de comandos para agendar y monitorear trabajos.
- ğŸ“Š **Monitoreo con Sentry**: IntegraciÃ³n completa para tracking de errores y performance.
- âš¡ **Middlewares Avanzados**: GestiÃ³n inteligente de requests y anti-detecciÃ³n mejorada.

## ğŸš€ Inicio RÃ¡pido con Docker

Pon en marcha toda la arquitectura distribuida en minutos.

```bash
# 1. Clonar el repositorio
git clone https://github.com/erik172/stylos-scrapers.git
cd stylos-scrapers

# 2. Crear tu archivo .env
# Puedes copiar el archivo de ejemplo: cp .env.example .env
# O crearlo directamente:
cat > .env << EOF
# ConfiguraciÃ³n de MongoDB (usa host.docker.internal para conectar desde un contenedor al host)
MONGO_URI=mongodb://host.docker.internal:27017
MONGO_DATABASE=stylos_scrapers
MONGO_COLLECTION=products

# ConfiguraciÃ³n de Selenium Grid
SELENIUM_MODE=remote
SELENIUM_HUB_URL=http://selenium-hub:4444/wd/hub

# ConfiguraciÃ³n de Scrapyd
SCRAPYD_URL=http://scrapyd:6800
PROJECT_NAME=stylos

# Monitoreo (Opcional)
SENTRY_DSN=
SCRAPY_ENV=development
EOF

# 3. Lanzar la arquitectura completa
docker-compose up --build -d
```

**Servicios Iniciados:**
- âœ… Servidor FastAPI      â†’ `http://localhost:8000`
- âœ… Servidor Scrapyd      â†’ `http://localhost:6800`
- âœ… Selenium Hub        â†’ `http://localhost:4444`

## ğŸ® Uso BÃ¡sico

Usa el CLI avanzado para controlar y monitorear los trabajos de scraping.

```bash
# Ejecutar un scraping completo para Zara (por defecto Colombia)
python control_scraper.py --spider zara

# Extraer datos de Zara para el mercado de USA en inglÃ©s
python control_scraper.py --spider zara --country us --lang en

# Extraer una Ãºnica URL de producto para testing
python control_scraper.py --spider zara --country us --lang en --url "https://www.zara.com/us/en/tu-producto-url.html"

# Ejecutar un scraping completo para Mango
python control_scraper.py --spider mango
```

El CLI proporciona monitoreo de estado en tiempo real, ID de trabajo y logs detallados.

## ğŸ¤ ContribuciÃ³n

Â¡Las contribuciones son bienvenidas! Ya sea agregando un nuevo retailer, mejorando la documentaciÃ³n o corrigiendo un bug, tu ayuda es apreciada.

- ğŸ“œ Por favor lee nuestro **[CÃ³digo de Conducta](CODE_OF_CONDUCT.md)**.
- ğŸ› ï¸ Para detalles sobre cÃ³mo contribuir, mira la **[GuÃ­a de ContribuciÃ³n](CONTRIBUTING.md)**.

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Mira el archivo **[LICENSE](LICENSE)** para mÃ¡s detalles.

---

## ğŸ“š DocumentaciÃ³n Detallada

<details>
<summary>Haz clic para expandir y ver todos los detalles tÃ©cnicos, arquitectura y uso avanzado.</summary>

### ğŸ—ï¸ Arquitectura del Sistema

#### ğŸŒ Arquitectura Distribuida Completa

```mermaid
graph TB
    subgraph "ğŸŒ Cliente/Usuario"
        CLI[ğŸ–¥ï¸ control_scraper.py<br/>Cliente CLI]
        WEB[ğŸŒ Navegador Web]
    end
    
    subgraph "ğŸ“¡ API Layer"
        API[âš¡ FastAPI Server<br/>Puerto 8000<br/>GestiÃ³n de Jobs]
    end
    
    subgraph "ğŸ•·ï¸ Scraping Engine"
        SCRAPYD[ğŸ™ Scrapyd Server<br/>Puerto 6800<br/>GestiÃ³n de Spiders]
        SPIDER[ğŸ•·ï¸ Scrapy Spiders<br/>Zara, Mango, etc.]
    end
    
    subgraph "ğŸŒ Selenium Grid Cluster"
        HUB[ğŸ¯ Selenium Hub<br/>Puerto 4444<br/>Orquestador]
        CHROME1[ğŸŒ Chrome Node 1<br/>Navegador Chrome]
        CHROME2[ğŸŒ Chrome Node 2<br/>Navegador Chrome] 
        CHROME3[ğŸŒ Chrome Node N<br/>Navegador Chrome]
    end
    
    subgraph "ğŸ’¾ Almacenamiento"
        MONGO[(ğŸƒ MongoDB<br/>Base de Datos)]
        FILES[ğŸ“ Archivos JSON<br/>Salida Opcional]
    end
    
    %% Flujo de datos
    CLI -->|POST /schedule| API
    WEB -->|GET /status/:id| API
    API -->|schedule.json| SCRAPYD
    SCRAPYD -->|Ejecuta| SPIDER
    SPIDER -->|selenium=True| HUB
    HUB -->|Distribuye carga| CHROME1
    HUB -->|Distribuye carga| CHROME2
    HUB -->|Distribuye carga| CHROME3
    CHROME1 -->|HTML Response| SPIDER
    CHROME2 -->|HTML Response| SPIDER
    CHROME3 -->|HTML Response| SPIDER
    SPIDER -->|Pipeline| MONGO
    SPIDER -->|Opcional| FILES
    
    %% Estilos
    classDef client fill:#e1f5fe
    classDef api fill:#f3e5f5
    classDef scraping fill:#e8f5e8
    classDef selenium fill:#fff3e0
    classDef storage fill:#fce4ec
    
    class CLI,WEB client
    class API api
    class SCRAPYD,SPIDER scraping
    class HUB,CHROME1,CHROME2,CHROME3 selenium
    class MONGO,FILES storage
```

### ğŸ”§ Componentes del Sistema

- **API Layer (FastAPI)**: Una interfaz REST en el puerto `8000` para gestionar trabajos de scraping (`/schedule`, `/status`).
- **Scraping Engine (Scrapyd)**: Gestiona y ejecuta los spiders de Scrapy en el puerto `6800`.
- **Selenium Grid Cluster**: Orquesta navegadores Chrome para renderizar JavaScript, con una UI de monitoreo en el puerto `4444`.
- **Extractors Modulares**: Un sistema conectable (patrÃ³n `Strategy`) para aÃ±adir fÃ¡cilmente nuevos retailers sin modificar la lÃ³gica del spider principal.

### ğŸ› ï¸ Stack TecnolÃ³gico Completo

- **Frameworks**: FastAPI, Scrapy, Scrapyd, Selenium
- **ContainerizaciÃ³n**: Docker, Docker Compose
- **Base de Datos**: MongoDB (vÃ­a PyMongo)
- **Desarrollo**: `bump-my-version` para versionado, `pytest` para testing, `Sentry` para monitoreo.

### ğŸ“ Arquitectura de Archivos

```
stylos-scrapers/
â”œâ”€â”€ ğŸ³ Docker & OrquestaciÃ³n
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ scrapy.cfg
â”œâ”€â”€ ğŸš€ API Layer
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ api_server.py
â”‚       â””â”€â”€ startup.sh
â”œâ”€â”€ ğŸ•·ï¸ Scraping Engine
â”‚   â””â”€â”€ stylos/
â”‚       â”œâ”€â”€ spiders/            # Spiders especÃ­ficos por retailer (ej. zara.py)
â”‚       â”œâ”€â”€ extractors/         # LÃ³gica de extracciÃ³n modular
â”‚       â”œâ”€â”€ middlewares.py      # Middlewares de Scrapy personalizados
â”‚       â”œâ”€â”€ pipelines.py        # Pipelines de procesamiento de datos
â”‚       â”œâ”€â”€ items.py            # Modelos de datos
â”‚       â””â”€â”€ settings.py         # ConfiguraciÃ³n del proyecto
â”œâ”€â”€ ğŸ® Control y GestiÃ³n
â”‚   â””â”€â”€ control_scraper.py      # Cliente CLI
â””â”€â”€ âš™ï¸ ConfiguraciÃ³n & Docs
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ README.md
    â””â”€â”€ RETAILERS.md
```

### ğŸ® Uso Avanzado

#### **ğŸŒ Soporte Multi-PaÃ­s/Idioma para Zara**

Ejecuta scrapers para diferentes mercados de Zara usando argumentos de lÃ­nea de comandos.

```bash
# Zara EspaÃ±a en espaÃ±ol
scrapy crawl zara -a country=es -a lang=es

# Zara USA en inglÃ©s
scrapy crawl zara -a country=us -a lang=en

# Zara Francia en francÃ©s
scrapy crawl zara -a country=fr -a lang=fr
```

- El sistema ajusta automÃ¡ticamente las URLs, selectores (por cambios de idioma) y moneda.

#### **ğŸ³ Comandos Docker Avanzados**

```bash
# Escalar nodos de Chrome para mayor paralelismo
docker-compose up --scale chrome=3 -d

# Ejecutar un comando dentro de un contenedor
docker-compose exec api python control_scraper.py --spider zara

# Ver logs de servicios especÃ­ficos
docker-compose logs -f scrapyd
```

### ğŸ“Š Estructura de Datos ExtraÃ­dos

El sistema extrae datos de producto completos, incluyendo precios, descuentos, imÃ¡genes por color y metadatos.

<details>
<summary>Haz clic para ver un ejemplo de la salida JSON de un producto.</summary>

```json
{
  "_id": {
    "$oid": "685a4381e6b026683884babc"
  },
  "url": "https://www.zara.com/co/es/pantalon-fluido-pinzas-p00264195.html?v1=440180813&v2=2419737",
  "name": "PANTALON FLUIDO PINZAS",
  "description": "pantalon de tiro medio y cintura con elastico interior. detalle de pinzas en delantero. pierna ancha.",
  "raw_prices": [
    "159.900 COP",
    "89.900 COP"
  ],
  "country": "co",
  "lang": "es",
  "images_by_color": [
    {
      "color": "NEGRO",
      "images": [
        {
          "src": "https://static.zara.net/assets/public/760f/2991/d8c34e28bb62/0b90d2b7a3d7/01165295800-a2/01165295800-a2.jpg?ts=1743077050757&w=710",
          "alt": "PANTALÃ“N FLUIDO PINZAS - Negro de Zara - Imagen 2",
          "img_type": "product_image"
        }
      ]
    }
  ],
  "site": "ZARA",
  "datetime": "2025-06-24T01:19:45.789676",
  "last_visited": "2025-06-24T01:19:45.789676",
  "original_price": 159900,
  "current_price": 89900,
  "has_discount": true,
  "currency": "COP",
  "discount_amount": 70000,
  "discount_percentage": 44
}
```
</details>

### ğŸ“ˆ Estado del Proyecto y Roadmap

- **Estado Actual**: VersiÃ³n de producciÃ³n estable.
- **Implementado**: Zara (multi-paÃ­s), Mango (Colombia).
- **Roadmap**: AÃ±adir soporte para H&M y Pull & Bear, integrar un sistema de proxy y mejorar el dashboard de monitoreo.

Para una lista detallada de retailers soportados y el pipeline de desarrollo, mira **[RETAILERS.md](RETAILERS.md)**.

</details>

---

**ğŸ¯ Desarrollado con â¤ï¸ para el futuro de la moda personalizada.**

> **Arquitectura Cloud-Native**: Un sistema completamente dockerizado y listo para producciÃ³n con escalamiento horizontal automÃ¡tico y monitoreo avanzado.
