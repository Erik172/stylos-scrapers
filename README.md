# Stylos Scraper ğŸ•·ï¸ğŸ‘—

**Parte del ecosistema Stylos** - Scraper inteligente para sitios de moda

<!-- GIF -->
![Zara Scraper Demo](media/zara-demo.gif)

## ğŸ¯ DescripciÃ³n del Proyecto

Stylos Scraper es una soluciÃ³n profesional de web scraping diseÃ±ada especÃ­ficamente para la extracciÃ³n de datos de sitios de e-commerce de moda. Utiliza tecnologÃ­as avanzadas como Selenium y Playwright para navegar sitios web dinÃ¡micos y extraer informaciÃ³n estructurada de productos, precios e imÃ¡genes.

El proyecto forma parte del ecosistema **Stylos**, una plataforma de inteligencia artificial que analiza tendencias de moda y genera recomendaciones personalizadas basadas en diferentes estilos:

- ğŸ’¼ **Old Money** - Elegancia atemporal
- ğŸ© **Formal** - Vestimenta profesional  
- ğŸ›¹ **Streetwear** - Moda urbana y casual
- âœ¨ **Y muchos mÃ¡s estilos personalizables**

## ğŸš€ CaracterÃ­sticas Principales

### âš¡ NavegaciÃ³n DinÃ¡mica Avanzada
- **AutomatizaciÃ³n completa de menÃºs**: NavegaciÃ³n inteligente por hamburguesas y categorÃ­as
- **Scroll infinito**: Manejo automÃ¡tico de lazy loading
- **PestaÃ±as mÃºltiples**: Apertura simultÃ¡nea de productos para optimizar tiempo
- **Sistema anti-detecciÃ³n**: User agents rotativos y configuraciÃ³n stealth

### ğŸ—„ï¸ GestiÃ³n Inteligente de Datos
- **MongoDB integrado**: Almacenamiento con detecciÃ³n automÃ¡tica de cambios
- **Pipeline de normalizaciÃ³n**: Procesamiento de precios, imÃ¡genes y metadatos
- **Control de duplicados**: Filtrado inteligente de contenido repetido
- **Historial de cambios**: Seguimiento de modificaciones de precios y disponibilidad

### ğŸ”§ Arquitectura Modular
- **Middlewares personalizados**: SeleniumMiddleware y BlocklistMiddleware
- **Items estructurados**: Modelos de datos normalizados con validaciÃ³n
- **Pipelines configurables**: Procesamiento de datos en cadena
- **Utilidades de anÃ¡lisis**: Herramientas para consultar estadÃ­sticas y cambios

## ğŸ› ï¸ Stack TecnolÃ³gico

### Frameworks y LibrerÃ­as Principales
```
Scrapy 2.13.2              # Framework de scraping principal
Selenium 4.33.0            # AutomatizaciÃ³n de navegador
PyMongo 4.13.1             # ConexiÃ³n con MongoDB
```

### Dependencias Especializadas
```
fake-useragent 2.2.0       # RotaciÃ³n de user agents
lxml 5.4.0                 # Procesamiento XML/HTML
unidecode 1.4.0            # NormalizaciÃ³n de texto
python-dotenv 1.1.0        # GestiÃ³n de variables de entorno
```

**Total**: 59 dependencias optimizadas para web scraping profesional

### Infraestructura
- **Base de Datos**: MongoDB con autenticaciÃ³n
- **Navegadores**: Chrome/Chromium con ChromeDriver
- **Lenguaje**: Python 3.7+
- **Variables de entorno**: ConfiguraciÃ³n segura con .env

## ğŸ“ Arquitectura del Proyecto

```
stylos-scrapers/
â”œâ”€â”€ stylos/                         # MÃ³dulo principal
â”‚   â”œâ”€â”€ spiders/                    # Spiders de scraping
â”‚   â”‚   â”œâ”€â”€ zara.py                # Spider completo de Zara (432 lÃ­neas)
â”‚   â”‚   â”œâ”€â”€ mango.py               # Spider bÃ¡sico de Mango
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ middlewares.py             # Middlewares personalizados (201 lÃ­neas)
â”‚   â”œâ”€â”€ pipelines.py               # Pipelines de procesamiento (307 lÃ­neas)
â”‚   â”œâ”€â”€ items.py                   # Modelos de datos (128 lÃ­neas)
â”‚   â”œâ”€â”€ settings.py                # ConfiguraciÃ³n del proyecto (123 lÃ­neas)
â”‚   â”œâ”€â”€ utils.py                   # Utilidades de anÃ¡lisis (149 lÃ­neas)
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ media/                         # Recursos multimedia
â”‚   â””â”€â”€ zara-demo.gif             # Demo del spider en funcionamiento
â”œâ”€â”€ requirements.txt               # 59 dependencias especializadas
â”œâ”€â”€ scrapy.cfg                     # ConfiguraciÃ³n de despliegue
â””â”€â”€ README.md                      # DocumentaciÃ³n
```

## ğŸª Retailers Soportados

### âœ… Completamente Implementado
**Zara (zara.py)**
- ğŸ”„ **NavegaciÃ³n completa**: CategorÃ­as de Mujer/Hombre con subcategorÃ­as
- ğŸ•·ï¸ **432 lÃ­neas de cÃ³digo**: LÃ³gica compleja de navegaciÃ³n y extracciÃ³n
- ğŸ¯ **ExtracciÃ³n avanzada**: Productos, precios, imÃ¡genes por color
- ğŸš€ **Selenium integrado**: ChromeDriver con configuraciÃ³n anti-bot
- ğŸ“± **Scroll infinito**: Carga automÃ¡tica de productos lazy-loaded
- ğŸ–¼ï¸ **ImÃ¡genes por color**: ExtracciÃ³n organizada por variantes

### ğŸš§ En Desarrollo
**Mango (mango.py)**
- ğŸ“ **Estructura base**: Spider bÃ¡sico inicializado
- ğŸŒ **Dominio configurado**: shop.mango.com
- âš ï¸ **Pendiente**: ImplementaciÃ³n de lÃ³gica de scraping

### ğŸ“‹ Roadmap de Retailers
```
H&M          â†’ Fast fashion sueco
Uniqlo       â†’ Minimalismo japonÃ©s  
Pull & Bear  â†’ Grupo Inditex
Bershka      â†’ Moda joven
Nike         â†’ Deportivo premium
Adidas       â†’ Deportivo lifestyle
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos del Sistema
- **Python 3.7+** (recomendado 3.9+)
- **Chrome/Chromium Browser**
- **MongoDB** (local o remoto)
- **Git** para clonaciÃ³n del repositorio

### InstalaciÃ³n Paso a Paso

1. **Clonar el repositorio**
   ```bash
   git clone <url-del-repositorio>
   cd stylos-scrapers
   ```

2. **Crear y activar entorno virtual**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # o
   venv\Scripts\activate     # Windows
   ```

3. **Instalar todas las dependencias**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configurar variables de entorno**
   ```bash
   # Crear archivo .env en la raÃ­z del proyecto
   MONGO_URI=mongodb://localhost:27017
   MONGO_DATABASE=stylos_scrapers
   MONGO_COLLECTION=products
   MONGO_USERNAME=tu_usuario
   MONGO_PASSWORD=tu_password
   ```

## ğŸ® Uso y EjecuciÃ³n

### Comandos BÃ¡sicos
```bash
# Ejecutar spider de Zara (completamente funcional)
scrapy crawl zara

# Ejecutar spider de Mango (en desarrollo)
scrapy crawl mango

# Guardar resultados en archivo JSON
scrapy crawl zara -o productos_zara.json

# Ejecutar con configuraciÃ³n personalizada
scrapy crawl zara -s DOWNLOAD_DELAY=3
scrapy crawl zara -s USER_AGENT='custom-agent'
```

### AnÃ¡lisis de Datos
```bash
# Ejecutar utilidades de anÃ¡lisis
python stylos/utils.py

# Ver estadÃ­sticas de productos
python -c "from stylos.utils import print_statistics; print_statistics()"
```

### ConfiguraciÃ³n Avanzada
```bash
# Habilitar logs detallados
scrapy crawl zara -L DEBUG

# Usar configuraciÃ³n personalizada
scrapy crawl zara -s ROBOTSTXT_OBEY=True

# Configurar concurrencia
scrapy crawl zara -s CONCURRENT_REQUESTS=8
```

## ğŸ“Š Estructura de Datos ExtraÃ­dos

### InformaciÃ³n del Producto
```json
{
  "url": "https://www.zara.com/co/es/producto...",
  "name": "BLAZER OVERSIZE LINO",
  "description": "blazer oversize confeccionado en lino...",
  "original_price": "399.000 COP",
  "current_price": "299.000 COP",
  "original_price_amount": 399000.0,
  "current_price_amount": 299000.0,
  "currency": "COP",
  "discount_percentage": 25,
  "has_discount": true
}
```

### ImÃ¡genes por Color
```json
{
  "images_by_color": [
    {
      "color": "NEGRO",
      "images": [
        {
          "src": "https://static.zara.net/photos/...",
          "alt": "BLAZER OVERSIZE LINO",
          "img_type": "principal"
        }
      ]
    }
  ]
}
```

### Metadatos del Sistema
```json
{
  "site": "zara",
  "datetime": "2024-01-15T14:30:00",
  "last_visited": "2024-01-15T14:30:00"
}
```

## ğŸ”§ ConfiguraciÃ³n del Sistema

### Middlewares Activos
- **SeleniumMiddleware**: NavegaciÃ³n dinÃ¡mica con Chrome
- **BlocklistMiddleware**: Filtrado de URLs no deseadas

### Pipelines Configurados
1. **DuplicatesPipeline** (200): Filtrado de duplicados
2. **StylosPipeline** (300): Procesamiento general  
3. **MongoDBPipeline** (400): Almacenamiento en base de datos

### Variables de Entorno Soportadas
```bash
MONGO_URI=mongodb://localhost:27017
MONGO_DATABASE=stylos_scrapers
MONGO_COLLECTION=products
MONGO_HISTORY_COLLECTION=product_history
MONGO_USERNAME=usuario
MONGO_PASSWORD=contraseÃ±a
MONGO_AUTH_SOURCE=admin
```

## ğŸ“ˆ Estado del Proyecto

**ğŸŸ¢ En ProducciÃ³n** - Sistema estable y funcional

### âœ… Funcionalidades Implementadas
- [x] Spider completo de Zara con navegaciÃ³n dinÃ¡mica
- [x] Sistema de middlewares personalizados
- [x] Pipeline de datos con MongoDB
- [x] NormalizaciÃ³n de precios y texto
- [x] ExtracciÃ³n de imÃ¡genes por variantes de color
- [x] Sistema anti-detecciÃ³n con rotaciÃ³n de user agents
- [x] DetecciÃ³n automÃ¡tica de cambios de precios
- [x] Utilidades de anÃ¡lisis y estadÃ­sticas

### ğŸ”„ En Desarrollo
- [ ] Spider completo de Mango
- [ ] IntegraciÃ³n completa con Selenium
- [ ] Dashboard web para monitoreo
- [ ] API REST para acceso a datos

### ğŸ¯ PrÃ³ximas Funcionalidades
- [ ] Spiders para H&M, Uniqlo, Pull & Bear
- [ ] Sistema de alertas de cambios de precio
- [ ] AnÃ¡lisis de tendencias con IA
- [ ] ExportaciÃ³n a mÃºltiples formatos

## ğŸ—ï¸ Arquitectura TÃ©cnica: Sistema de Extractors

### ğŸ¯ Problema Resuelto

El desafÃ­o principal era que cada sitio web tiene **selectores y lÃ³gica de navegaciÃ³n completamente diferentes**. Un middleware hardcodeado para Zara no funcionarÃ­a para Mango, H&M, etc.

**SoluciÃ³n**: **PatrÃ³n Strategy** con extractors especializados por sitio web.

### ğŸ§  Concepto del Sistema

Cada sitio web tiene su propio "extractor" especializado que implementa la misma interfaz pero con lÃ³gica especÃ­fica. El middleware se vuelve genÃ©rico y solo delega la extracciÃ³n al extractor correcto.

```mermaid
graph TD
    A["ğŸ•·ï¸ Spider Solicita ExtracciÃ³n"] --> B["âš™ï¸ SeleniumMiddleware"]
    B --> C["ğŸ“‹ ExtractorRegistry"]
    C --> D{"ğŸ¤” Â¿QuÃ© spider?"}
    D -->|"name = 'zara'"| E["ğŸŸ¦ ZaraExtractor"]
    D -->|"name = 'mango'"| F["ğŸŸ§ MangoExtractor"]
    D -->|"name = 'hm'"| G["ğŸŸ© HMExtractor"]
    E --> H["ğŸ”§ LÃ³gica especÃ­fica de Zara<br/>â€¢ MenÃº hamburguesa<br/>â€¢ CategorÃ­as MUJER/HOMBRE<br/>â€¢ Selectores especÃ­ficos"]
    F --> I["ğŸ”§ LÃ³gica especÃ­fica de Mango<br/>â€¢ MenÃº directo<br/>â€¢ Botones load-more<br/>â€¢ Swatches de color"]
    G --> J["ğŸ”§ LÃ³gica especÃ­fica de H&M<br/>â€¢ API endpoints<br/>â€¢ PaginaciÃ³n<br/>â€¢ Selectores Ãºnicos"]
    H --> K["ğŸ“¦ Datos Estructurados"]
    I --> K
    J --> K
    K --> L["ğŸ¯ Spider Recibe Datos<br/>{'extracted_urls': [...]}"]
```

### ğŸ”§ Componentes del Sistema

#### **1. Extractor Base Abstracto**
```python
# stylos/extractors/__init__.py
class BaseExtractor(ABC):
    """Define la interfaz comÃºn para todos los extractors"""
    
    @abstractmethod
    def extract_menu_urls(self): pass
    
    @abstractmethod  
    def extract_product_data(self): pass
```

#### **2. Registry con Auto-registro**
```python
# Usando un decorador, cada extractor se registra automÃ¡ticamente
@register_extractor('zara')
class ZaraExtractor(BaseExtractor):
    # LÃ³gica de Zara
    pass

@register_extractor('mango')
class MangoExtractor(BaseExtractor):
    # LÃ³gica de Mango
    pass
```

#### **3. Middleware GenÃ©rico**
```python
# El middleware ahora es agnÃ³stico del sitio
def process_request(self, request, spider):
    # Delega la extracciÃ³n al extractor correcto
    extractor = ExtractorRegistry.get_extractor(spider.name, self.driver, spider)
    extracted_data = extractor.extract_menu_urls()
```

### ğŸ”„ Flujo de EjecuciÃ³n Completo

```mermaid
sequenceDiagram
    participant S as Spider
    participant M as SeleniumMiddleware
    participant R as ExtractorRegistry
    participant Z as ZaraExtractor
    participant D as WebDriver

    S->>M: Request con extraction_type='menu'
    M->>R: get_extractor('zara', driver, spider)
    R->>Z: Crear ZaraExtractor(driver, spider)
    Z-->>R: Instancia de ZaraExtractor
    R-->>M: ZaraExtractor instance
    M->>Z: extract_menu_urls()
    Z->>D: Ejecutar lÃ³gica especÃ­fica de Zara
    D-->>Z: HTML renderizado + interacciones
    Z-->>M: {'extracted_urls': [...]}
    M-->>S: Response con datos estructurados
```

### ğŸ® Ejemplo PrÃ¡ctico: Diferencias por Sitio

#### **Zara vs Mango - Mismo resultado, lÃ³gica diferente:**

```python
# ğŸ”´ ZARA: MenÃº hamburguesa complejo
@register_extractor('zara')
class ZaraExtractor(BaseExtractor):
    def extract_menu_urls(self):
        # 1. Buscar botÃ³n hamburguesa con mÃºltiples selectores
        # 2. Navegar por categorÃ­as MUJER/HOMBRE

# ğŸŸ  MANGO: MenÃº directo diferente  
@register_extractor('mango')
class MangoExtractor(BaseExtractor):
    def extract_menu_urls(self):
        # 1. Buscar botÃ³n de menÃº (selectores diferentes)
        # 2. Extraer enlaces directamente (estructura diferente)
```

### ğŸ—ï¸ Arquitectura del Sistema de Extractors

```mermaid
classDiagram
    class BaseExtractor {
        <<abstract>>
        +driver: WebDriver
        +spider: Spider
        +extract_menu_urls()* dict
        +extract_category_data()* dict
        +extract_product_data()* dict
    }
    class ExtractorRegistry {
        +register(spider_name, extractor_class)$ void
        +get_extractor(spider_name, driver, spider)$ BaseExtractor
    }
    class ZaraExtractor {
        +extract_menu_urls() dict
    }
    class MangoExtractor {
        +extract_menu_urls() dict
    }
    class SeleniumMiddleware {
        +process_request() HtmlResponse
    }
    BaseExtractor <|-- ZaraExtractor
    BaseExtractor <|-- MangoExtractor
    ExtractorRegistry --> BaseExtractor : gets
    SeleniumMiddleware --> ExtractorRegistry : uses
```

### ğŸš€ Ventajas del Sistema

- **ğŸ“ˆ Escalabilidad Extrema**: Agregar un nuevo sitio es tan simple como crear un nuevo archivo de extractor.
- **ğŸ§ª Testing Individual**: Cada extractor se puede probar de forma aislada.
- **ğŸ”§ Mantenimiento Aislado**: Los cambios en un sitio no afectan a otros.
- **ğŸ›¡ï¸ Robustez**: El sistema es predecible y tiene un fallback si no encuentra un extractor.

---

**Desarrollado con â¤ï¸ para el futuro de la moda personalizada**

> **Nota**: Este es un proyecto en desarrollo activo. La documentaciÃ³n y funcionalidades pueden cambiar frecuentemente. 