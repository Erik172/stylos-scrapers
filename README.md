# Stylos Scraper ğŸ•·ï¸ğŸ‘—

**Parte del ecosistema Stylos** - Scraper inteligente para sitios de moda

<!-- GIF -->
![Zara Scraper Demo](media/zara-demo.gif)

## ğŸ¯ DescripciÃ³n del Proyecto

Stylos Scraper es una soluciÃ³n profesional de web scraping diseÃ±ada especÃ­ficamente para la extracciÃ³n de datos de sitios de e-commerce de moda. Utiliza tecnologÃ­as avanzadas como Selenium y Playwright para navegar sitios web dinÃ¡micos y extraer informaciÃ³n estructurada de productos, precios e imÃ¡genes.

ğŸ‡¨ğŸ‡´ **Enfoque Inicial:** Comenzamos con el mercado colombiano como piloto
ğŸŒ **ExpansiÃ³n Planificada:** Arquitectura diseÃ±ada para escalabilidad internacional

El proyecto forma parte del ecosistema **Stylos**, una plataforma de inteligencia artificial que analiza tendencias de moda y genera recomendaciones personalizadas basadas en diferentes estilos:

- ğŸ’¼ **Old Money** - Elegancia atemporal
- ğŸ© **Formal** - Vestimenta profesional  
- ğŸ›¹ **Streetwear** - Moda urbana y casual
- âœ¨ **Y muchos mÃ¡s estilos personalizables**

## ğŸš€ CaracterÃ­sticas Principales

### âš¡ NavegaciÃ³n DinÃ¡mica Avanzada
- **AutomatizaciÃ³n completa de menÃºs**: NavegaciÃ³n inteligente por hamburguesas y categorÃ­as
- **Scroll infinito**: Manejo automÃ¡tico de lazy loading
- **PestaÃ±as mÃºltiples**: Apertura simultÃ¡nea de productos para optimizar tiempo
- **Sistema anti-detecciÃ³n**: User agents rotativos y configuraciÃ³n stealth

### ğŸ—„ï¸ GestiÃ³n Inteligente de Datos
- **MongoDB integrado**: Almacenamiento con detecciÃ³n automÃ¡tica de cambios
- **Pipeline de normalizaciÃ³n**: Procesamiento de precios, imÃ¡genes y metadatos
- **Control de duplicados**: Filtrado inteligente de contenido repetido
- **Historial de cambios**: Seguimiento de modificaciones de precios y disponibilidad

### ğŸ”§ Arquitectura Modular
- **Middlewares personalizados**: SeleniumMiddleware y BlocklistMiddleware
- **Items estructurados**: Modelos de datos normalizados con validaciÃ³n
- **Pipelines configurables**: Procesamiento de datos en cadena
- **Utilidades de anÃ¡lisis**: Herramientas para consultar estadÃ­sticas y cambios

## ğŸ› ï¸ Stack TecnolÃ³gico

### Frameworks y LibrerÃ­as Principales
```
Scrapy 2.13.2              # Framework de scraping principal
Selenium 4.33.0            # AutomatizaciÃ³n de navegador
PyMongo 4.13.1             # ConexiÃ³n con MongoDB
```

### Dependencias Especializadas
```
fake-useragent 2.2.0       # RotaciÃ³n de user agents
lxml 5.4.0                 # Procesamiento XML/HTML
unidecode 1.4.0            # NormalizaciÃ³n de texto
python-dotenv 1.1.0        # GestiÃ³n de variables de entorno
```

**Total**: 59 dependencias optimizadas para web scraping profesional

### Infraestructura
- **Base de Datos**: MongoDB con autenticaciÃ³n
- **Navegadores**: Chrome/Chromium con ChromeDriver
- **Lenguaje**: Python 3.7+
- **Variables de entorno**: ConfiguraciÃ³n segura con .env

## ğŸ“ Arquitectura del Proyecto

```
stylos-scrapers/
â”œâ”€â”€ stylos/                         # MÃ³dulo principal
â”‚   â”œâ”€â”€ spiders/                    # Spiders de scraping
â”‚   â”‚   â”œâ”€â”€ zara.py                # Spider completo de Zara (432 lÃ­neas)
â”‚   â”‚   â”œâ”€â”€ mango.py               # Spider bÃ¡sico de Mango
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ middlewares.py             # Middlewares personalizados (201 lÃ­neas)
â”‚   â”œâ”€â”€ pipelines.py               # Pipelines de procesamiento (307 lÃ­neas)
â”‚   â”œâ”€â”€ items.py                   # Modelos de datos (128 lÃ­neas)
â”‚   â”œâ”€â”€ settings.py                # ConfiguraciÃ³n del proyecto (123 lÃ­neas)
â”‚   â”œâ”€â”€ utils.py                   # Utilidades de anÃ¡lisis (149 lÃ­neas)
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ media/                         # Recursos multimedia
â”‚   â””â”€â”€ zara-demo.gif             # Demo del spider en funcionamiento
â”œâ”€â”€ requirements.txt               # 59 dependencias especializadas
â”œâ”€â”€ scrapy.cfg                     # ConfiguraciÃ³n de despliegue
â””â”€â”€ README.md                      # DocumentaciÃ³n
```

## ğŸª Retailers Soportados (Colombia ğŸ‡¨ğŸ‡´)

### âœ… Completamente Implementado
**Zara Colombia (zara.py)**
- ğŸŒ **URL:** https://www.zara.com/co/es/
- ğŸ”„ **NavegaciÃ³n completa**: CategorÃ­as de Mujer/Hombre con subcategorÃ­as
- ğŸ•·ï¸ **432 lÃ­neas de cÃ³digo**: LÃ³gica compleja de navegaciÃ³n y extracciÃ³n
- ğŸ¯ **ExtracciÃ³n avanzada**: Productos, precios en COP, imÃ¡genes por color
- ğŸš€ **Selenium integrado**: ChromeDriver con configuraciÃ³n anti-bot
- ğŸ“± **Scroll infinito**: Carga automÃ¡tica de productos lazy-loaded
- ğŸ–¼ï¸ **ImÃ¡genes por color**: ExtracciÃ³n organizada por variantes

### ğŸš§ En Desarrollo
**Mango Colombia (mango.py)**
- ğŸŒ **URL:** https://shop.mango.com/co/
- ğŸ“ **Estructura base**: Spider bÃ¡sico inicializado
- âš ï¸ **Pendiente**: ImplementaciÃ³n de lÃ³gica de scraping completa

### ğŸ“‹ Roadmap de Retailers Colombia
```
H&M Colombia       â†’ https://www2.hm.com/es_co/
Pull & Bear CO     â†’ https://www.pullandbear.com/co/  
Bershka Colombia   â†’ https://www.bershka.com/co/
Nike Colombia      â†’ https://www.nike.com/co/
Adidas Colombia    â†’ https://www.adidas.co/
```

## ğŸŒ ExpansiÃ³n Internacional

### Arquitectura Multi-PaÃ­s
El sistema estÃ¡ construido para expandirse fÃ¡cilmente a otros mercados:

```python
# ConfiguraciÃ³n de paÃ­ses (ejemplo)
COUNTRIES = {
    'colombia': {'currency': 'COP', 'domain': '.co', 'lang': 'es_CO'},
    'mexico': {'currency': 'MXN', 'domain': '.mx', 'lang': 'es_MX'},
    'peru': {'currency': 'PEN', 'domain': '.pe', 'lang': 'es_PE'}
}

# Uso: scrapy crawl zara -a country=mexico
```

### Ventajas de la Arquitectura
- âœ… **ReutilizaciÃ³n de cÃ³digo**: Los extractors funcionan en cualquier paÃ­s
- âœ… **ConfiguraciÃ³n simple**: Solo cambiar URLs y parÃ¡metros de moneda
- âœ… **Base de datos escalable**: MongoDB maneja mÃºltiples mercados
- âœ… **Pipelines adaptables**: Procesamiento automÃ¡tico de monedas regionales

### Mercados Objetivo Futuros
1. ğŸ‡²ğŸ‡½ **MÃ©xico** - Mercado grande, mismo idioma
2. ğŸ‡µğŸ‡ª **PerÃº** - RegiÃ³n andina, similar a Colombia  
3. ğŸ‡¨ğŸ‡± **Chile** - Mercado desarrollado
4. ğŸ‡¦ğŸ‡· **Argentina** - Gran potencial
5. ğŸ‡ªğŸ‡¸ **EspaÃ±a** - Mercado europeo hispanohablante

### Â¿Por quÃ© empezar con Colombia? ğŸ‡¨ğŸ‡´
- **Mercado emergente**: Gran crecimiento en e-commerce
- **Idioma espaÃ±ol**: Facilita el desarrollo y testing
- **Retailers globales**: Todos los grandes tienen presencia local
- **Menos competencia**: Menor saturaciÃ³n de herramientas similares
- **Moneda estable**: COP facilita el manejo de precios
- **Zona horaria**: UTC-5 conveniente para desarrollo

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos del Sistema

#### Para Docker Hub (Recomendado)
- **Docker** y **Docker Compose** instalados
- **MongoDB** (local o remoto)
- **Git** para clonaciÃ³n del repositorio

#### Para Modo Local
- **Python 3.7+** (recomendado 3.9+)
- **Chrome/Chromium Browser** instalado
- **MongoDB** (local o remoto)
- **Git** para clonaciÃ³n del repositorio

### ğŸ³ InstalaciÃ³n con Docker Hub (Recomendado)

1. **Clonar el repositorio**
   ```bash
   git clone <url-del-repositorio>
   cd stylos-scrapers
   ```

2. **Configurar variables de entorno**
   ```bash
   # Crear archivo .env con configuraciÃ³n para Docker
   cp .env.example .env  # Si existe archivo de ejemplo
   # O crear manualmente:
   cat > .env << EOF
   MONGO_URI=mongodb://host.docker.internal:27017
   MONGO_DATABASE=stylos_scrapers
   MONGO_COLLECTION=products
   SELENIUM_MODE=remote
   SELENIUM_HUB_URL=http://selenium-hub:4444
   EOF
   ```

3. **Ejecutar con Docker**
   ```bash
   # Construir y iniciar todos los servicios
   docker-compose up --build
   ```

### ğŸ’» InstalaciÃ³n Local (Desarrollo)

1. **Clonar el repositorio**
   ```bash
   git clone <url-del-repositorio>
   cd stylos-scrapers
   ```

2. **Crear y activar entorno virtual**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # o
   venv\Scripts\activate     # Windows
   ```

3. **Instalar todas las dependencias**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configurar variables de entorno para modo local**
   ```bash
   # Crear archivo .env en la raÃ­z del proyecto
   MONGO_URI=mongodb://localhost:27017
   MONGO_DATABASE=stylos_scrapers
   MONGO_COLLECTION=products
   MONGO_USERNAME=tu_usuario
   MONGO_PASSWORD=tu_password
   
   # ConfiguraciÃ³n de Selenium para modo LOCAL
   SELENIUM_MODE=local                           # 'local' para Chrome local
   # SELENIUM_HUB_URL no es necesaria en modo local
   ```

### ğŸŒ ConfiguraciÃ³n Multi-PaÃ­s
Para cambiar de paÃ­s, simplemente modifica las URLs en los spiders:

```python
# En stylos/spiders/zara.py
start_urls = [
    "https://www.zara.com/co/",    # Colombia (actual)
    # "https://www.zara.com/mx/",  # MÃ©xico
    # "https://www.zara.com/pe/",  # PerÃº
]
```

**Ejecutar en diferentes paÃ­ses:**
```bash
# Colombia (configuraciÃ³n actual)
scrapy crawl zara

# Para cambiar a otro paÃ­s, editar las URLs en el spider
# y ejecutar normalmente - todo el resto funciona igual
```

## ğŸ® Uso y EjecuciÃ³n

### ğŸ³ Ejecutar con Docker Hub (Modo Recomendado)

El proyecto incluye un sistema completo con Selenium Grid para mayor escalabilidad y robustez:

```bash
# 1. Construir y ejecutar todos los servicios (Scraper + Selenium Hub + Chrome)
docker-compose up --build

# 2. Ejecutar en segundo plano
docker-compose up -d --build

# 3. Ver logs en tiempo real
docker-compose logs -f scraper

# 4. Detener todos los servicios
docker-compose down

# 5. Ver interfaz web del Hub (opcional)
# Visita: http://localhost:4444
```

#### Arquitectura del Hub Docker
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Scraper       â”‚â”€â”€â”€â–¶â”‚  Selenium Hub   â”‚â”€â”€â”€â–¶â”‚   Chrome Node   â”‚
â”‚   (Scrapy)      â”‚    â”‚   (Grid)        â”‚    â”‚   (Browser)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’» Ejecutar sin Hub (Modo Local)

Para desarrollo o testing rÃ¡pido, puedes ejecutar sin Docker:

```bash
# 1. Configurar variables de entorno para modo local
echo "SELENIUM_MODE=local" >> .env

# 2. Ejecutar spider normalmente
scrapy crawl zara

# 3. Para modo especÃ­fico de spider
scrapy crawl zara -a url="https://www.zara.com/co/es/producto..."
```

### ğŸ“‹ Comandos EspecÃ­ficos por Modo

#### Con Docker Hub
```bash
# Ejecutar spider especÃ­fico
docker-compose run scraper scrapy crawl mango

# Guardar resultados
docker-compose run scraper scrapy crawl zara -o /app/productos_zara.json

# ConfiguraciÃ³n personalizada
docker-compose run scraper scrapy crawl zara -s DOWNLOAD_DELAY=5
```

#### Sin Hub (Local)
```bash
# Ejecutar spider de Zara (completamente funcional)
scrapy crawl zara

# Ejecutar spider de Mango (en desarrollo)
scrapy crawl mango

# Guardar resultados en archivo JSON
scrapy crawl zara -o productos_zara.json

# Ejecutar con configuraciÃ³n personalizada
scrapy crawl zara -s DOWNLOAD_DELAY=3
scrapy crawl zara -s USER_AGENT='custom-agent'
```

### AnÃ¡lisis de Datos
```bash
# Ejecutar utilidades de anÃ¡lisis
python stylos/utils.py

# Ver estadÃ­sticas de productos
python -c "from stylos.utils import print_statistics; print_statistics()"
```

### ConfiguraciÃ³n Avanzada
```bash
# Habilitar logs detallados
scrapy crawl zara -L DEBUG

# Usar configuraciÃ³n personalizada
scrapy crawl zara -s ROBOTSTXT_OBEY=True

# Configurar concurrencia
scrapy crawl zara -s CONCURRENT_REQUESTS=8
```

## ğŸ“Š Estructura de Datos ExtraÃ­dos

### InformaciÃ³n del Producto
```json
{
  "url": "https://www.zara.com/co/es/producto...",
  "name": "BLAZER OVERSIZE LINO",
  "description": "blazer oversize confeccionado en lino...",
  "original_price": "399.000 COP",
  "current_price": "299.000 COP",
  "original_price_amount": 399000.0,
  "current_price_amount": 299000.0,
  "currency": "COP",
  "discount_percentage": 25,
  "has_discount": true
}
```

### ImÃ¡genes por Color
```json
{
  "images_by_color": [
    {
      "color": "NEGRO",
      "images": [
        {
          "src": "https://static.zara.net/photos/...",
          "alt": "BLAZER OVERSIZE LINO",
          "img_type": "principal"
        }
      ]
    }
  ]
}
```

### Metadatos del Sistema
```json
{
  "site": "zara",
  "datetime": "2024-01-15T14:30:00",
  "last_visited": "2024-01-15T14:30:00"
}
```

## ğŸ”§ ConfiguraciÃ³n del Sistema

### Middlewares Activos
- **SeleniumMiddleware**: NavegaciÃ³n dinÃ¡mica con Chrome
- **BlocklistMiddleware**: Filtrado de URLs no deseadas

### Pipelines Configurados
1. **DuplicatesPipeline** (200): Filtrado de duplicados
2. **StylosPipeline** (300): Procesamiento general  
3. **MongoDBPipeline** (400): Almacenamiento en base de datos

## ğŸš€ Modos de EjecuciÃ³n: Hub vs Local

### ğŸ³ Docker Hub (Recomendado para ProducciÃ³n)

#### âœ… Ventajas
- **Escalabilidad**: MÃºltiples instancias de Chrome ejecutÃ¡ndose simultÃ¡neamente
- **Estabilidad**: Navegadores aislados, menor impacto de crashes
- **Reproducibilidad**: Mismo entorno en desarrollo y producciÃ³n
- **GestiÃ³n automÃ¡tica**: Docker maneja la instalaciÃ³n y configuraciÃ³n de Chrome
- **Recursos**: Mejor uso de memoria y CPU
- **Interfaz web**: Monitor del hub en http://localhost:4444

#### âš ï¸ Consideraciones
- Requiere Docker y Docker Compose instalados
- Mayor uso de recursos del sistema inicialmente

#### ğŸ¯ CuÃ¡ndo usar
- âœ… Scraping de producciÃ³n con grandes volÃºmenes
- âœ… Equipos de desarrollo (entorno consistente)
- âœ… Sistemas de CI/CD
- âœ… Servidores sin interfaz grÃ¡fica

### ğŸ’» Modo Local (Ideal para Desarrollo)

#### âœ… Ventajas
- **Rapidez**: Inicio inmediato sin Docker
- **Debugging**: Puedes ver el navegador funcionando (modo no-headless)
- **Simplicidad**: No requiere Docker
- **Desarrollo**: Ideal para testing y desarrollo de extractors

#### âš ï¸ Consideraciones
- Requiere Chrome/Chromium instalado localmente
- Una sola instancia de navegador a la vez
- Puede ser menos estable con mÃºltiples ejecuciones

#### ğŸ¯ CuÃ¡ndo usar
- âœ… Desarrollo y testing de nuevos extractors
- âœ… Debugging de selectores CSS/XPath
- âœ… Pruebas rÃ¡pidas con un solo producto
- âœ… Desarrollo en mÃ¡quinas locales

## ğŸ”„ Cambiar entre Modos

### Cambiar a Docker Hub
```bash
# 1. Actualizar .env
echo "SELENIUM_MODE=remote" >> .env
echo "SELENIUM_HUB_URL=http://selenium-hub:4444" >> .env

# 2. Ejecutar con Docker
docker-compose up --build
```

### Cambiar a Local
```bash
# 1. Actualizar .env
echo "SELENIUM_MODE=local" >> .env

# 2. Ejecutar normalmente
scrapy crawl zara
```

### Variables de Entorno Soportadas

#### ConfiguraciÃ³n General
```bash
MONGO_URI=mongodb://localhost:27017
MONGO_DATABASE=stylos_scrapers
MONGO_COLLECTION=products
MONGO_USERNAME=usuario
MONGO_PASSWORD=contraseÃ±a
DEFAULT_COUNTRY=colombia
```

#### ConfiguraciÃ³n Selenium
```bash
# Para Docker Hub
SELENIUM_MODE=remote
SELENIUM_HUB_URL=http://selenium-hub:4444

# Para Local
SELENIUM_MODE=local
# SELENIUM_HUB_URL no requerida
```

## ğŸ“Š ComparaciÃ³n de Modos

| CaracterÃ­stica | Docker Hub ğŸ³ | Local ğŸ’» |
|----------------|---------------|----------|
| **InstalaciÃ³n** | Docker requerido | Python + Chrome |
| **Tiempo inicio** | ~30s (primera vez) | ~5s |
| **Escalabilidad** | MÃºltiples Chrome | Una instancia |
| **Debugging** | Logs en terminal | Browser visible |
| **Recursos** | Mayor memoria inicial | Menor overhead |
| **Estabilidad** | Alta (aislamiento) | Media |
| **ProducciÃ³n** | âœ… Recomendado | âŒ No recomendado |
| **Desarrollo** | âœ… Bueno | âœ… Excelente |
| **CI/CD** | âœ… Perfecto | âŒ Limitado |

## ğŸ› ï¸ Archivos de ConfiguraciÃ³n

### docker-compose.yml
```yaml
version: '3.8'

services:
  scraper:
    build: .
    command: scrapy crawl zara
    env_file:
      - ./.env
    volumes:
      - ./stylos:/app/stylos
    depends_on:
      - selenium-hub
      - chrome

  selenium-hub:
    image: selenium/hub:4.22.0
    ports:
      - "4444:4444"

  chrome:
    image: selenium/node-chrome:4.22.0
    shm_size: '2g'
    depends_on:
      - selenium-hub
    environment:
      - SE_EVENT_BUS_HOST=selenium-hub
      - SE_EVENT_BUS_PUBLISH_PORT=4442
      - SE_EVENT_BUS_SUBSCRIBE_PORT=4443
      - NODE_MAX_SESSIONS=5
      - NODE_MAX_INSTANCES=5
```

### Dockerfile
```docker
FROM python:3.11-slim

WORKDIR /app

ENV PYTHONDONTWRITEBYTECODE 1
ENV PYTHONUNBUFFERED 1

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY ./stylos /app/stylos
```

## ğŸ“ˆ Estado del Proyecto

**ğŸŸ¢ En ProducciÃ³n** - Sistema estable y funcional con arquitectura de hub

### âœ… Funcionalidades Implementadas
- [x] Sistema dual: Docker Hub + Modo Local
- [x] Spider completo de Zara con navegaciÃ³n dinÃ¡mica  
- [x] Selenium Grid con escalabilidad automÃ¡tica
- [x] Sistema de middlewares personalizados
- [x] Pipeline de datos con MongoDB
- [x] NormalizaciÃ³n de precios y texto
- [x] ExtracciÃ³n de imÃ¡genes por variantes de color
- [x] Sistema anti-detecciÃ³n con rotaciÃ³n de user agents
- [x] DetecciÃ³n automÃ¡tica de cambios de precios
- [x] Interfaz web para monitoreo del hub (puerto 4444)

### ğŸš§ En Desarrollo
- [ ] Spider completo de Mango
- [ ] OptimizaciÃ³n de recursos Docker
- [ ] Dashboard de monitoreo avanzado

**Ãšltima actualizaciÃ³n:** Diciembre 2024

## ğŸ“ˆ Estado del Proyecto

**ğŸŸ¢ En ProducciÃ³n** - Sistema estable y funcional

### âœ… Funcionalidades Implementadas
- [x] Spider completo de Zara con navegaciÃ³n dinÃ¡mica
- [x] Sistema de middlewares personalizados
- [x] Pipeline de datos con MongoDB
- [x] NormalizaciÃ³n de precios y texto
- [x] ExtracciÃ³n de imÃ¡genes por variantes de color
- [x] Sistema anti-detecciÃ³n con rotaciÃ³n de user agents
- [x] DetecciÃ³n automÃ¡tica de cambios de precios
- [x] Utilidades de anÃ¡lisis y estadÃ­sticas

### ğŸ”„ En Desarrollo
- [ ] Spider completo de Mango
- [ ] IntegraciÃ³n completa con Selenium
- [ ] Dashboard web para monitoreo
- [ ] API REST para acceso a datos

### ğŸ¯ PrÃ³ximas Funcionalidades
- [ ] Spiders para H&M, Uniqlo, Pull & Bear
- [ ] Sistema de alertas de cambios de precio
- [ ] AnÃ¡lisis de tendencias con IA
- [ ] ExportaciÃ³n a mÃºltiples formatos

## ğŸ—ï¸ Arquitectura TÃ©cnica: Sistema de Extractors

### ğŸ¯ Problema Resuelto

El desafÃ­o principal era que cada sitio web tiene **selectores y lÃ³gica de navegaciÃ³n completamente diferentes**. Un middleware hardcodeado para Zara no funcionarÃ­a para Mango, H&M, etc.

**SoluciÃ³n**: **PatrÃ³n Strategy** con extractors especializados por sitio web.

### ğŸ§  Concepto del Sistema

Cada sitio web tiene su propio "extractor" especializado que implementa la misma interfaz pero con lÃ³gica especÃ­fica. El middleware se vuelve genÃ©rico y solo delega la extracciÃ³n al extractor correcto.

```mermaid
graph TD
    A["ğŸ•·ï¸ Spider Solicita ExtracciÃ³n"] --> B["âš™ï¸ SeleniumMiddleware"]
    B --> C["ğŸ“‹ ExtractorRegistry"]
    C --> D{"ğŸ¤” Â¿QuÃ© spider?"}
    D -->|"name = 'zara'"| E["ğŸŸ¦ ZaraExtractor"]
    D -->|"name = 'mango'"| F["ğŸŸ§ MangoExtractor"]
    D -->|"name = 'hm'"| G["ğŸŸ© HMExtractor"]
    E --> H["ğŸ”§ LÃ³gica especÃ­fica de Zara<br/>â€¢ MenÃº hamburguesa<br/>â€¢ CategorÃ­as MUJER/HOMBRE<br/>â€¢ Selectores especÃ­ficos"]
    F --> I["ğŸ”§ LÃ³gica especÃ­fica de Mango<br/>â€¢ MenÃº directo<br/>â€¢ Botones load-more<br/>â€¢ Swatches de color"]
    G --> J["ğŸ”§ LÃ³gica especÃ­fica de H&M<br/>â€¢ API endpoints<br/>â€¢ PaginaciÃ³n<br/>â€¢ Selectores Ãºnicos"]
    H --> K["ğŸ“¦ Datos Estructurados"]
    I --> K
    J --> K
    K --> L["ğŸ¯ Spider Recibe Datos<br/>{'extracted_urls': [...]}"]
```

### ğŸ”§ Componentes del Sistema

#### **1. Extractor Base Abstracto**
```python
# stylos/extractors/__init__.py
class BaseExtractor(ABC):
    """Define la interfaz comÃºn para todos los extractors"""
    
    @abstractmethod
    def extract_menu_urls(self): pass
    
    @abstractmethod  
    def extract_product_data(self): pass
```

#### **2. Registry con Auto-registro**
```python
# Usando un decorador, cada extractor se registra automÃ¡ticamente
@register_extractor('zara')
class ZaraExtractor(BaseExtractor):
    # LÃ³gica de Zara
    pass

@register_extractor('mango')
class MangoExtractor(BaseExtractor):
    # LÃ³gica de Mango
    pass
```

#### **3. Middleware GenÃ©rico**
```python
# El middleware ahora es agnÃ³stico del sitio
def process_request(self, request, spider):
    # Delega la extracciÃ³n al extractor correcto
    extractor = ExtractorRegistry.get_extractor(spider.name, self.driver, spider)
    extracted_data = extractor.extract_menu_urls()
```

### ğŸ”„ Flujo de EjecuciÃ³n Completo

```mermaid
sequenceDiagram
    participant S as Spider
    participant M as SeleniumMiddleware
    participant R as ExtractorRegistry
    participant Z as ZaraExtractor
    participant D as WebDriver

    S->>M: Request con extraction_type='menu'
    M->>R: get_extractor('zara', driver, spider)
    R->>Z: Crear ZaraExtractor(driver, spider)
    Z-->>R: Instancia de ZaraExtractor
    R-->>M: ZaraExtractor instance
    M->>Z: extract_menu_urls()
    Z->>D: Ejecutar lÃ³gica especÃ­fica de Zara
    D-->>Z: HTML renderizado + interacciones
    Z-->>M: {'extracted_urls': [...]}
    M-->>S: Response con datos estructurados
```

### ğŸ® Ejemplo PrÃ¡ctico: Diferencias por Sitio

#### **Zara vs Mango - Mismo resultado, lÃ³gica diferente:**

```python
# ğŸ”´ ZARA: MenÃº hamburguesa complejo
@register_extractor('zara')
class ZaraExtractor(BaseExtractor):
    def extract_menu_urls(self):
        # 1. Buscar botÃ³n hamburguesa con mÃºltiples selectores
        # 2. Navegar por categorÃ­as MUJER/HOMBRE

# ğŸŸ  MANGO: MenÃº directo diferente  
@register_extractor('mango')
class MangoExtractor(BaseExtractor):
    def extract_menu_urls(self):
        # 1. Buscar botÃ³n de menÃº (selectores diferentes)
        # 2. Extraer enlaces directamente (estructura diferente)
```

### ğŸ—ï¸ Arquitectura del Sistema de Extractors

```mermaid
classDiagram
    class BaseExtractor {
        <<abstract>>
        +driver: WebDriver
        +spider: Spider
        +extract_menu_urls()* dict
        +extract_category_data()* dict
        +extract_product_data()* dict
    }
    class ExtractorRegistry {
        +register(spider_name, extractor_class)$ void
        +get_extractor(spider_name, driver, spider)$ BaseExtractor
    }
    class ZaraExtractor {
        +extract_menu_urls() dict
    }
    class MangoExtractor {
        +extract_menu_urls() dict
    }
    class SeleniumMiddleware {
        +process_request() HtmlResponse
    }
    BaseExtractor <|-- ZaraExtractor
    BaseExtractor <|-- MangoExtractor
    ExtractorRegistry --> BaseExtractor : gets
    SeleniumMiddleware --> ExtractorRegistry : uses
```

### ğŸš€ Ventajas del Sistema

- **ğŸ“ˆ Escalabilidad Extrema**: Agregar un nuevo sitio es tan simple como crear un nuevo archivo de extractor.
- **ğŸ§ª Testing Individual**: Cada extractor se puede probar de forma aislada.
- **ğŸ”§ Mantenimiento Aislado**: Los cambios en un sitio no afectan a otros.
- **ğŸ›¡ï¸ Robustez**: El sistema es predecible y tiene un fallback si no encuentra un extractor.

---

**Desarrollado con â¤ï¸ para el futuro de la moda personalizada**

> **Nota**: Este es un proyecto en desarrollo activo con sistema dual Docker Hub + Local. La documentaciÃ³n y funcionalidades pueden cambiar frecuentemente. 